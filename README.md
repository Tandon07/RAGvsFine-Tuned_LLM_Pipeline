
---

# ğŸ“Š Financial Q\&A Assistant â€” Globex Innovations

## ğŸš€ Project Overview

This project was built to answer **financial questions** on *Globex Innovationsâ€™ 2023â€“2024 data*.

We wanted to explore two different approaches for Q\&A systems:

1. **RAG (Retrieval-Augmented Generation)**

   * Uses **FAISS** to search through stored Q\&A pairs
   * Passes relevant chunks into **Groq LLM (`llama-3.1-8b-instant`)** for response generation

2. **Fine-Tuned DistilBERT QA**

   * A lighter model fine-tuned directly on company-specific Q\&A pairs
   * Works offline, and if the fine-tuned model isnâ€™t available, it falls back to retrieval mode

On top of this, we also built a **Streamlit dashboard** so everything can be tested interactively (not just via CLI).

---

## ğŸ—ï¸ How It Works (Architecture)

```mermaid
flowchart TD
    A[Company_data.docx] -->|Parsing| B[Data Processor]
    B -->|QA Pairs JSON| C[FAISS Retriever]
    C -->|Relevant Context| D[RAG Generator - Groq LLM]
    C -->|Retriever Fallback| E[Fine-Tuned DistilBERT]
    D --> F[Answer to User]
    E --> F[Answer to User]
    F --> G[Streamlit Dashboard / CLI]
```

---

## ğŸ“‚ Project Structure

```
project/
â”‚â”€â”€ app.py                  # CLI tool for Q&A
â”‚â”€â”€ streamlit_app.py        # Streamlit dashboard
â”‚â”€â”€ config.py               # Paths, API keys, model configs
â”‚â”€â”€ requirements.txt        # Dependencies
â”‚â”€â”€ README.md               # This file :)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ Company_data.docx
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ qa_pairs.json
â”‚
â”œâ”€â”€ rag_system/
â”‚   â”œâ”€â”€ data_processor.py   # Convert docx â†’ Q&A JSON
â”‚   â”œâ”€â”€ retriever_faiss.py  # FAISS-based retriever
â”‚   â””â”€â”€ generator.py        # Groq LLM answer generation
â”‚
â”œâ”€â”€ fine_tuned_system/
â”‚   â””â”€â”€ model.py            # Fine-tuned DistilBERT (or retriever fallback)
â”‚
â””â”€â”€ fine_tuning/
    â””â”€â”€ fine_tune_bert.ipynb  # Notebook for fine-tuning DistilBERT
```

---

## âš™ï¸ Setup

### 1. Clone & create environment

```bash
git clone <repo_url>
cd project
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Add Groq API key

```bash
# Windows (PowerShell)
setx GROQ_API_KEY "your_api_key_here"

# Linux / Mac
export GROQ_API_KEY="your_api_key_here"
```

### 3. Prepare data

Put your financial data in:

```
data/raw/Company_data.docx
```

Then preprocess it:

```bash
python -m rag_system.data_processor
```

---

## â–¶ï¸ Run the Project

### CLI mode

```bash
python app.py
```

### Streamlit dashboard

```bash
streamlit run streamlit_app.py
```

In the UI, you can:

* Type your question
* Select whether to use **RAG** (FAISS + Groq) or **Fine-Tuned DistilBERT**
* See the **answer, confidence score, method used, and response time**
* Expand the retrieved context for debugging

---

## ğŸ§‘â€ğŸ« Fine-Tuning DistilBERT

To fine-tune DistilBERT on your own dataset:

1. Open the notebook:

   ```
   fine_tuning/fine_tune_bert.ipynb
   ```
2. Train on `qa_pairs.json`
3. Save the trained model to:

   ```
   fine_tuned_system/distilbert-qa-lora
   ```

The system will automatically load it. If not found, it falls back to FAISS retrieval.

---

## ğŸ” RAG vs Fine-Tuned â€” What We Learned

| Feature         | RAG (FAISS + Groq)         | Fine-Tuned DistilBERT         |
| --------------- | -------------------------- | ----------------------------- |
| Data Dependency | Uses stored Q\&A chunks    | Learns directly from QA pairs |
| Model Size      | Llama-3.1-8B (Groq)        | DistilBERT (\~66M params)     |
| Response Style  | Conversational, generative | Extractive, precise           |
| External API    | âœ… Needs Groq API           | âŒ Works fully offline         |
| Training Needed | âŒ No training required     | âœ… Needs fine-tuning           |
| Speed           | Medium (API call latency)  | Fast (local inference)        |
| Best Use Case   | General reasoning          | Domain-specific answers       |

---

## ğŸ› ï¸ Tech Stack

* **LLMs:** Groq LLaMA-3.1, DistilBERT
* **Vector DB:** FAISS (Sentence-Transformers embeddings)
* **Frameworks:** HuggingFace, LangChain, Streamlit
* **Fine-Tuning:** HuggingFace Transformers + PEFT (LoRA)
* **Other tools:** python-docx, scikit-learn, dotenv

---

## ğŸ”® Next Steps / Improvements

* Add evaluation metrics (Exact Match, F1, BLEU)
* Support for multiple companies/datasets
* Try hybrid retrievers (BM25 + FAISS)
* Deploy via **FastAPI** and package with Docker
* Improve Streamlit UI with charts & retrieval insights

---

## ğŸ‘¥ About Us  

**Conversation AI â€” Group 77**  

We are a team of **M.Tech students at BITS Pilani**, currently in our **3rd semester** specializing in **Artificial Intelligence and Machine Learning**.  
This project is part of our coursework, where we explore practical applications of **NLP, LLMs, and fine-tuning techniques** in real-world financial Q&A systems.  

---